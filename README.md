
# multi-agent-RL
make two robots function together with arduino mega 2560.


## 8-Week Timetable

**Project Goal:** Two Communicating Robots with Reinforcement Learning

**Overall Strategy:**

1.  **Robot 1 Mastery:** Get one robot fully, robustly functional with precise control (including encoders and IMU).
2.  **Rapid Duplication:** Leverage learned skills for quick setup of Robot 2.
3.  **Robust Communication:** Prioritize flawless inter-robot and robot-PC communication.
4.  **Practical RL Demonstration:** Focus on getting a working, demonstrable RL system, even if the learned task is simple.

-----

### Phase 1: Robot 1 Mastery & Robot 2 Replication (Weeks 1-3)

| Week | Day | Primary Goal(s) | Key Tasks & Deliverables | Notes & Focus Areas |
| :--- | :-- | :---------------- | :----------------------- | :------------------ |
| **Week 1: Robot 1 Mechanical Overhaul & Core Motor Control (with Encoder Prep)** | | **Goal:** Robot 1 mechanically sound; basic open-loop DC motor control; research/order encoders. | **Key Learnings:** Mechanical repair, DC motor basics, L298N operation, Arduino PWM, coding best practices. | **Focus:** Meticulous assembly, correct wiring, functional motor control. |
| | Day 1-2 | Mechanical Overhaul & Detailed Documentation (Robot 1) | - Systematic disassembly (take photos\!). <br> - Inspect, clean, repair/replace components (chassis, wheels, motor mounts). <br> - Re-assemble meticulously, ensuring smooth wheel rotation and secure motor mounting. <br> - **Deliverable:** Detailed mechanical drawing and component inventory. | **Crucial:** Document every step with photos/notes. |
| | Day 3-4 | L298N Wiring & Initial DC Motor Control (Robot 1) | - Wire **two L298N modules** to Arduino Mega for **4 DC motors**. <br> - **Meticulously double-check** all connections (power, logic, ground). <br> - Confirm adequate external power supply (7-12V, high current capacity). <br> - Develop Arduino functions/class for basic control (`setMotorSpeed`, `moveForward`, `turnLeft`, `stopRobot`). <br> - **Deliverable:** Thoroughly tested motor control functions & basic robot movements. | **Common Failure Point:** Incorrect wiring/power. Debug diligently. |
| | Day 5 | Encoder Research & Procurement Planning | - **Crucial:** Research suitable **encoders** for your DC motors (e.g., optical, Hall effect). <br> - Understand wiring (VCC, GND, A, B pins) and Arduino interrupt connection. <br> - **Action:** Finalize decision on encoder type and **begin procurement immediately (order them)**. | This step needs to be done fast to keep the timeline on track. |
| **Week 2: Encoders, Velocity PID, & Basic Sensors (Robot 1)** | | **Goal:** Integrate encoders, implement velocity PID for DC motors, and get ultrasonic/servo working. | **Key Learnings:** Encoder reading (interrupts), PID algorithm, sensor filtering. | **Focus:** Precise speed control, reliable sensor readings. |
| | Day 1-2 | Encoder Integration & Raw Reading (Robot 1) | - **Action:** Receive/Install encoders on Robot 1's DC motors. <br> - Wire encoder A/B pins to Arduino Mega **interrupt-enabled digital pins**. <br> - Write Arduino code to read raw encoder counts and interpret direction using interrupts. <br> - **Deliverable:** Verified raw encoder readings (print to Serial Monitor). Debug noise/missed counts. | Interruption-based encoder reading is key for accuracy. |
| | Day 3-4 | DC Motor Velocity PID Implementation (Robot 1) | - Develop or adapt a **PID library/class** (e.g., `PID_v1` library). <br> - Implement a **velocity PID loop** for each DC motor. <br> - **Tuning:** Systematically tune Kp, Ki, Kd for each motor to achieve stable and accurate speed control. Start with Kp, then add Ki. Test on various surfaces/loads. <br> - Refine high-level movement functions to use PID-controlled speeds. <br> - **Deliverable:** Robot 1 demonstrates stable and accurate velocity control. | PID tuning can be iterative; be patient. |
| | Day 5 | Ultrasonic Sensor & SG90 Servo Integration (Robot 1) | - Mount **ultrasonic sensors**. Wire multiple sensors to Arduino. <br> - Develop robust Arduino functions to read distances, including filtering (e.g., median filter). <br> - Mount and wire **SG90 servo**. Use `Servo.h` to control its angle. Test full range. <br> - **Deliverable:** All sensors and servo working reliably. | Ensure proper mounting for effective sensor readings. |
| **Week 3: IMU Integration, Odometry, & Robot 2 Replication** | | **Goal:** Integrate IMU for enhanced odometry on Robot 1; replicate all systems on Robot 2. | **Key Learnings:** IMU basics, sensor fusion (complementary filter), efficient duplication. | **Focus:** Robust orientation estimation, efficient and accurate replication. |
| | Day 1-2 | IMU Integration & Sensor Fusion (Robot 1) | - **Action:** Acquire an **IMU** (e.g., MPU6050/MPU9250). <br> - Wire IMU (I2C to Arduino). Use an appropriate Arduino library. <br> - Read raw accelerometer, gyroscope, and magnetometer data. <br> - Implement a **complementary filter** or basic sensor fusion for stable orientation (yaw/heading). <br> - Integrate IMU heading with encoder odometry for a more robust relative position estimate (x,y,θ). <br> - **Deliverable:** Robot 1 can estimate its position and orientation reliably. | Sensor fusion is crucial for accurate odometry over time. |
| | Day 3-5 | Robot 2 Full Assembly & Comprehensive Testing | - Perform the exact mechanical, electrical, and coding setup for **Robot 2**, mirroring Robot 1's now robust setup. <br> - Upload the same Arduino code (DC motor velocity PID, encoder handling, ultrasonic, servo, IMU, odometry) to Robot 2. <br> - **Comprehensive Testing:** Thoroughly test all functionalities on Robot 2. Compare performance with Robot 1. Address any discrepancies. <br> - **Deliverable:** Robot 2 fully functional, matching Robot 1's performance. | Leverage learnings from Robot 1; this should be faster but still requires diligence. |

-----

### Phase 2: Communication Deep Dive (Weeks 4-5)

| Week | Day | Primary Goal(s) | Key Tasks & Deliverables | Notes & Focus Areas |
| :--- | :-- | :---------------- | :----------------------- | :------------------ |
| **Week 4: Robot-Robot Wi-Fi Communication & Protocol Design** | | **Goal:** Establish robust two-way Wi-Fi communication between the two robots. | **Key Learnings:** Wi-Fi module specifics, network configuration (AP/Station), communication protocols. | **Focus:** Stable connection, clear message protocol, robust parsing. |
| | Day 1-2 | Wi-Fi Module Specifics & Wiring (Both Robots) | - **Crucial:** Double-check specific model of your **Wi-Fi modules** (ESP8266/ESP32). <br> - Understand their wiring for **3.3V logic** (use logic level converters or voltage dividers if needed for Arduino Mega 5V pins). <br> - Wire Wi-Fi modules to dedicated Arduino Mega Serial ports (e.g., Serial1 for R1's Wi-Fi, Serial2 for R2's Wi-Fi). <br> - Write initial Arduino sketches to configure Robot 1 as a **Wi-Fi Access Point (AP)** and Robot 2 as a **Wi-Fi Station** connecting to Robot 1's AP. <br> - **Deliverable:** Both robots successfully connected via Wi-Fi. Debug connection stability. | **Common Failure Point:** Incorrect logic levels. Verify thoroughly. |
| | Day 3-5 | Bidirectional Communication & Message Protocol | - Implement **UDP** (recommended for simplicity and speed) client/server on both robots. <br> - Design a concise, robust message protocol (e.g., "MOV\_F,150"; "POS,R1,12.5,30.2,90.0"). <br> - Implement **serialization** (packing data to send) and **deserialization** (unpacking received data) in Arduino code. <br> - **Deliverable:** Robots can send and receive structured commands/sensor data to/from each other. | Thoroughly test message sending, reception, and parsing. |
| **Week 5: Robot-PC Communication & Centralized Control Setup (Python)** | | **Goal:** Establish Wi-Fi communication between robots and a central PC (for RL). Develop PC-side control interface. | **Key Learnings:** Python socket programming, managing multiple client connections. | **Focus:** Centralized control via Python, aggregation of robot states. |
| | Day 1-2 | Python Wi-Fi Communication Setup (PC to One Robot) | - Install necessary Python libraries (e.g., `socket`). <br> - **Network Strategy:** Have a central Wi-Fi router; robots and PC connect to it. PC acts as central hub. <br> - Write a Python script to establish a UDP (or TCP) connection with one robot. Send commands, receive its state. <br> - **Deliverable:** PC can reliably communicate with Robot 1. | Keep the network setup simple for initial tests. |
| | Day 3-4 | Multi-Robot Python Interface & Centralized Control | - Extend the Python script to manage communication with **both robots concurrently** (e.g., using Python's `threading` module or `asyncio`). <br> - Develop a Python class/structure to represent each robot's current state (position, sensor readings, battery, etc.). <br> - Create a simple PC-based "teleoperation" interface (e.g., keyboard controls) that sends commands to both robots via Wi-Fi. <br> - **Deliverable:** PC can independently and coordinately control both robots. | Ensure unique identifiers for each robot in messages or by using distinct IP/ports. |
| | Day 5 | RL Environment Prep & Mid-Project Review | - Start learning about **Reinforcement Learning (RL) fundamentals** (Q-learning basics, states, actions, rewards, environment). Watch tutorials. <br> - Install relevant Python libraries for RL (e.g., `numpy`, `matplotlib`, `gym`). <br> - **Mid-Project Review:** Consolidate documentation. Ensure all mechanical, electrical, and communication components are robust. <br> - **Deliverable:** Prepared for RL phase with foundational knowledge and tools installed. | This is your pivot point towards the AI component. |

-----

### Phase 3: Reinforcement Learning & Collaborative Task (Weeks 6-8)

| Week | Day | Primary Goal(s) | Key Tasks & Deliverables | Notes & Focus Areas |
| :--- | :-- | :---------------- | :----------------------- | :------------------ |
| **Week 6: RL Fundamentals & Single-Robot Simulation** | | **Goal:** Build a basic Python-based RL simulation environment and implement a simple single-robot Q-learning algorithm. | **Key Learnings:** Core RL theory, Python simulation, Q-learning implementation. | **Focus:** Building intuition for RL in a controlled, software-only environment. |
| | Day 1-2 | In-Depth RL Theory (Q-Learning Focus) | - Solidify understanding of **Q-learning**: Q-table, Bellman equation, ϵ-greedy exploration, learning rate (α), discount factor (γ). <br> - Understand how to define **states, actions, and reward functions** for your simple robot task. <br> - **Deliverable:** Solid theoretical understanding of Q-learning. | Dive deep into the underlying principles. |
| | Day 3-5 | Python Simulation Environment & Basic Q-Learning Algorithm | - Create a very simple **2D grid-world simulation** in Python. Define robot actions (move, turn), walls, goal. <br> - Implement the state representation for this simulation (e.g., (x,y) coordinates). <br> - Implement a basic **Q-learning algorithm** from scratch or using minimal libraries. <br> - Train an agent within your simulated environment for a single-robot task (e.g., navigate a simple maze). <br> - **Deliverable:** Q-learning agent successfully solves a simulated task. | This is purely software-based; iterate rapidly. |
| **Week 7: Single Robot RL Control (Physical Robot)** | | **Goal:** Connect the Python RL algorithm to Robot 1 and begin real-world learning experiments. | **Key Learnings:** Mapping simulated concepts to physical robot, real-world RL challenges. | **Focus:** Bridging the gap between simulation and real-world hardware. **Expect intensive debugging.** |
| | Day 1-2 | Adapting Robot Code for RL Loop & Python-Robot Integration | - Modify Robot 1's Arduino code to act as a responsive "executor": receive action commands, execute, read all relevant sensors (odometry, ultrasonic), package into compact state message, send back. <br> - Modify your Python RL script: Instead of simulation, send actions to **Robot 1 via Wi-Fi** and receive its real-world "state." <br> - Define the **reward function** in Python based on Robot 1's real-world progress/events. <br> - **Deliverable:** Robot 1's firmware and Python script are integrated for RL. | Ensure robust communication and state/action mapping. |
| | Day 3-5 | Single Robot RL Experimentation & Debugging | - Place Robot 1 in a controlled physical environment (e.g., a small taped-off arena). <br> - Run the RL training loop. Observe the robot's exploration and learning. <br> - **Expect Intensive Debugging:** RL on real hardware is very challenging due to sensor noise, motor inaccuracies, latency, and unpredictability. <br> - **Deliverable:** Robot 1 shows signs of learning a simple physical task. | **This will be challenging.** Start with an extremely simple task (e.g., "drive forward until obstacle, then turn right"). |
| **Week 8: Multi-Robot Collaborative RL & Project Finalization** | | **Goal:** Implement a simple collaborative RL task with both robots and prepare a comprehensive final presentation. | **Key Learnings:** Joint state/action spaces, synchronized communication for MARL, presentation skills. | **Focus:** Demonstrating collaborative behavior, even if simplified. Polishing presentation. |
| | Day 1-2 | Collaborative Task Design & Multi-Robot RL Implementation (Python) | - Define a minimalist **collaborative task** (e.g., "Robot 1 reaches point A, Robot 2 reaches point B simultaneously"). <br> - Define the **joint state** (e.g., combined (R1\_x, R1\_y, R1\_theta, R2\_x, R2\_y, R2\_theta, sensor\_data)) and **joint action space** (e.g., (R1\_action, R2\_action)). <br> - Define a clear **shared reward function** for collaboration success. <br> - Modify your Python RL script to manage **two agents**: send actions to both robots, receive states from both, and update a joint Q-table. <br> - **Deliverable:** Python RL agent can attempt multi-robot control. | Keep the task very simple to increase success likelihood. |
| | Day 3-4 | Collaborative RL Experimentation & Troubleshooting | - Execute the chosen collaborative task with both robots. <br> - **This will be the most challenging phase.** Focus on getting any demonstrable sign of collaborative learning, even if imperfect or requiring significant tuning. <br> - **Alternative:** If direct MARL is too complex, simplify: one robot learns, the other acts reactively based on communication from the first. <br> - **Deliverable:** Evidence of collaborative robot behavior (even if simple). | Be prepared for extensive debugging and potential simplification. |
| | Day 5 | Project Presentation & Final Documentation | - Prepare a **comprehensive presentation** detailing: Goals, challenges, solutions, mechanical/electrical setup, communication, RL methodology, results (videos), learnings, future work. <br> - Ensure all code (Arduino and Python) is clean, **well-commented**, and organized in a repository. <br> - **Deliverable:** Final presentation and working demo of robots. | Practice your presentation\! Ensure basic demos are reliable. |

-----
